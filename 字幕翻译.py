import time
import pysubs2
import threading
import sys
import re
import os
from llama_cpp import Llama
from concurrent.futures import ThreadPoolExecutor

# --- é…ç½® ---
MODEL_PATH = r"E:\Downloads\sakura-7b-qwen2.5-v1.0-q6k.gguf"
INPUT_PATH = r"E:\Downloads\INPUT_ass.ass"  # æ”¯æŒ .srt æˆ– .ass
OUTPUT_PATH = r"E:\Downloads\output_fixedass.ass"

MAX_WORKERS = 2
BATCH_SIZE = 8  # ASS ä¸“ç”¨çš„æ‰¹å¤„ç†å¤§å°
model_lock = threading.Lock()
progress_lock = threading.Lock()
completed_lines = 0
total_lines = 0

print(f"ğŸš€ å¯åŠ¨ SakuraLLMï¼šåŒæ¨¡è‡ªé€‚åº”å¼•æ“...")
# ä¸ºäº†å…¼å®¹æ‰¹å¤„ç†ï¼Œn_ctx ç¨å¾®è°ƒå¤§
llm = Llama(model_path=MODEL_PATH, n_gpu_layers=-1, n_ctx=2048, verbose=False)


# --- é€šç”¨å·¥å…·å‡½æ•° ---

def split_prefix_properly(text):
    """æå–è¡Œé¦–åå­—æ‹¬å·/ç‰¹æ®Šç¬¦å·å‰ç¼€"""
    # å¢å¼ºæ­£åˆ™ï¼šåŒ¹é…è¡Œé¦–çš„æ ‡ç­¾ã€ç¬¦å·ã€æ¨ªæ æˆ–æ‹¬å·å
    pattern = r'^((?:\{.*?\}|[-ï¼\s]*[ï¼ˆ\(].*?[ï¼‰\)]+[\s]*|[^\w\u4e00-\u9fa5\u3041-\u30ff]+)+)'
    match = re.match(pattern, text)
    if match:
        prefix = match.group(1)
        body = text[len(prefix):].strip()
        return prefix, body
    return "", text


def clean_mid_text_furigana(text):
    """æ¸…ç†æ–‡ä¸­æ³¨éŸ³ï¼Œé˜²æ­¢ AI æˆªæ–­æˆ–å¤è¯»"""
    return re.sub(r'([\u4e00-\u9fa5])[\(ï¼ˆ][\u3040-\u30ff]+[\)ï¼‰]', r'\1', text)


def update_progress(increment=1):
    global completed_lines
    with progress_lock:
        completed_lines += increment
        percent = (completed_lines / total_lines) * 100
        sys.stdout.write(f"\rğŸ“ˆ è¿›åº¦: {percent:.1f}% ({completed_lines}/{total_lines})")
        sys.stdout.flush()


# --- æ–¹æ¡ˆ A: SRT é€»è¾‘ (å¹¶å‘å•è¡Œ) ---

def translate_line_srt(idx, all_tasks):
    line_obj, original_text = all_tasks[idx]
    prefix, pure_body = split_prefix_properly(original_text)
    clean_body = clean_mid_text_furigana(pure_body)

    if not clean_body.strip():
        line_obj.text = f"{line_obj.text}\\N{prefix}"
        return update_progress()

    prompt = f"<|im_start|>system\nä½ æ˜¯ä¸€ä¸ªæ—¥æ¼«ç¿»è¯‘ï¼Œè¯·å°†æ—¥æ–‡ç¿»è¯‘æˆæµåˆ©çš„ä¸­æ–‡å°è¯ã€‚ç›´æ¥è¾“å‡ºè¯‘æ–‡ã€‚<|im_end|>\n<|im_start|>user\n{clean_body}<|im_end|>\n<|im_start|>assistant\n"

    try:
        with model_lock:
            output = llm(prompt, max_tokens=150, stop=["<|im_end|>", "\n"], temperature=0.1, repeat_penalty=1.2)
        res = output["choices"][0]["text"].strip()
        res = re.sub(r'^[ï¼ˆ\(].*?[ï¼‰\)]|ç¿»è¯‘[:ï¼š]|ã€Œ|ã€', '', res).strip()

        if res:
            final_zh = f"{prefix}{res}".replace("[BR]", "\\N")
            line_obj.text = f"{line_obj.text}\\N{final_zh}"
        else:
            line_obj.text = f"{line_obj.text}\\N{prefix}{clean_body}"
        update_progress()
    except:
        update_progress()


# --- æ–¹æ¡ˆ B: ASS é€»è¾‘ (æ‰¹å¤„ç†ä¿æŠ¤) ---

def protect_ass_tags(text):
    """æå–æ ‡ç­¾å ä½ç¬¦ï¼Œå¹¶å¢å¼ºè¡Œå°¾ç¬¦å·ä¿æŠ¤"""
    # prefix, body = split_prefix_properly(text) # æ—§ä»£ç 

    # æ–°å¢é€»è¾‘ï¼šæå–å‰ç¼€çš„åŒæ—¶ï¼Œæå–è¡Œå°¾è¡”æ¥ç¬¦ (â¡, ã€‹, â‰«, ...)
    prefix, rem_text = split_prefix_properly(text)
    suffix_pattern = r'([â¡â‰«ã€‹>]+)$'
    suffix_match = re.search(suffix_pattern, rem_text)
    suffix = suffix_match.group(1) if suffix_match else ""
    body = rem_text[:-len(suffix)] if suffix else rem_text

    tags = re.findall(r'\{.*?\}', body)
    masked_body = body
    for i, tag in enumerate(tags):
        masked_body = masked_body.replace(tag, f" [T{i}] ", 1)

    # åŒæ ·æ¸…ç†æ³¨éŸ³
    masked_body = clean_mid_text_furigana(masked_body)
    return prefix, masked_body, tags, suffix


def translate_batch_ass(batch_tasks):
    prompt_lines = []
    for idx, task in enumerate(batch_tasks):
        # å¢åŠ åˆ¤æ–­ï¼šå¦‚æœ masked_body ä¸åŒ…å«ä»»ä½•æ±‰å­—/å‡åï¼ˆçº¯ç¬¦å·è¡Œï¼‰ï¼Œåˆ™æ ‡è®°ä¸ºä¸éœ€è¦ç¿»è¯‘
        if not re.search(r'[\u3040-\u30ff\u4e00-\u9fa5]', task['masked_body']):
            prompt_lines.append(f"{idx + 1}: SKIP_LINE")
        else:
            prompt_lines.append(f"{idx + 1}: {task['masked_body']}")

    combined_input = "\n".join(prompt_lines)

    prompt = f"<|im_start|>system\nä½ æ˜¯ä¸€ä¸ªæ—¥æ¼«ç¿»è¯‘ä¸“å®¶ã€‚è¯·æŒ‰ç¼–å·ç¿»è¯‘å°è¯ï¼Œä¿æŒ[T_n]å ä½ç¬¦ä½ç½®ä¸å˜ã€‚å¦‚æœçœ‹åˆ° SKIP_LINE åˆ™åŸæ ·è¾“å‡ºã€‚<|im_end|>\n<|im_start|>user\n{combined_input}<|im_end|>\n<|im_start|>assistant\n1: "

    with model_lock:
        output = llm(prompt, max_tokens=1024, temperature=0.1, stop=["<|im_end|>", "User:"])

    raw_res = "1: " + output["choices"][0]["text"]
    results = {}
    for i in range(len(batch_tasks)):
        pattern = rf"{i + 1}[:ï¼š]\s*(.*?)(?=\n\d+[:ï¼š]|$)"
        match = re.search(pattern, raw_res, re.DOTALL)
        if match:
            # å¼ºåŒ–è¿‡æ»¤ï¼šæ¸…ç† ID æ³„éœ²å’Œå†—ä½™è¯æ±‡
            content = match.group(1).strip()
            content = re.sub(r'^\d+[:ï¼š]\s*', '', content)
            results[i] = re.sub(r'å ä½ç¬¦|ç¿»è¯‘|ä¿æŒ|ã€Œ|ã€|SKIP_LINE', '', content).strip()
    return results


# --- å…¥å£æ§åˆ¶ ---

def start():
    global total_lines
    ext = os.path.splitext(INPUT_PATH)[1].lower()
    subs = pysubs2.load(INPUT_PATH)

    all_tasks = []
    for line in subs:
        p = line.plaintext.strip()
        if p:
            p = p.replace("\\N", "[BR]").replace("\n", "[BR]")
            all_tasks.append((line, p))

    total_lines = len(all_tasks)
    time_s = time.time()

    if ext == ".ass":
        print(f"ğŸ¬ æ£€æµ‹åˆ° ASS æ ¼å¼ï¼Œå¯åŠ¨ã€æ‰¹å¤„ç†ä¿æŠ¤ã€‘æ–¹æ¡ˆ (Batch Size: {BATCH_SIZE})...")
        # å‡†å¤‡æ‰¹å¤„ç†æ•°æ®
        ass_tasks = []
        for line_obj, text in all_tasks:
            # prefix, masked_body, tags = protect_ass_tags(text) # æ—§ä»£ç 
            prefix, masked_body, tags, suffix = protect_ass_tags(text)  # æ–°é€»è¾‘å¢åŠ  suffix
            ass_tasks.append({
                'obj': line_obj,
                'masked_body': masked_body,
                'prefix': prefix,
                'tags': tags,
                'suffix': suffix  # è®°å½•è¡Œå°¾è¡”æ¥ç¬¦
            })

        for i in range(0, total_lines, BATCH_SIZE):
            batch = ass_tasks[i: i + BATCH_SIZE]
            batch_results = translate_batch_ass(batch)
            for idx, task in enumerate(batch):
                res = batch_results.get(idx, "")
                if res:
                    for t_idx, tag in enumerate(task['tags']):
                        res = res.replace(f"[T{t_idx}]", tag).replace(f"T{t_idx}", tag)

                    # final_zh = f"{task['prefix']}{res}".replace(" ", "").replace("[BR]", "\\N") # æ—§ä»£ç 

                    # ç¼åˆé€»è¾‘ä¼˜åŒ–ï¼šå»é‡å‰ç¼€æ‹¬å·å¹¶ç²˜åˆè¡Œå°¾è¡”æ¥ç¬¦
                    res = re.sub(r'([ã€Šï¼ˆ(])\1+', r'\1', res)  # ç¬¦å·å»é‡
                    final_zh = f"{task['prefix']}{res}{task['suffix']}"
                    final_zh = final_zh.replace(" ", "").replace("[BR]", "\\N")

                    task['obj'].text = f"{task['obj'].text}\\N{final_zh}"
                else:
                    task['obj'].text = f"{task['obj'].text}\\N{task['prefix']}{task['masked_body']}{task['suffix']}"
            update_progress(len(batch))

    else:
        print(f"ğŸ“ æ£€æµ‹åˆ° SRT æ ¼å¼ï¼Œå¯åŠ¨ã€å¹¶å‘å•è¡Œã€‘æ–¹æ¡ˆ (Workers: {MAX_WORKERS})...")
        with ThreadPoolExecutor(max_workers=MAX_WORKERS) as executor:
            list(executor.map(lambda i: translate_line_srt(i, all_tasks), range(total_lines)))

    subs.save(OUTPUT_PATH)
    time_elapsed = time.time() - time_s
    print(f"\nâœ¨ å¤„ç†å®Œæˆï¼è¾“å‡ºæ–‡ä»¶ï¼š{OUTPUT_PATH} ç”¨æ—¶ï¼š{time_elapsed}s")


if __name__ == "__main__":
    start()
