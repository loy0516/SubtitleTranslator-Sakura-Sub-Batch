import re
import time
import pysubs2
from llama_cpp import Llama

# --- é…ç½® ---
MODEL_PATH = r"E:\Downloads\sakura-7b-qwen2.5-v1.0-q6k.gguf"
INPUT_ASS = r"E:\Downloads\[NanakoRaws] Champignon no Majo - 05 (TBS 1920x1080 x265 AAC).ass"
OUTPUT_ASS = r"E:\Downloads\output_sakura_batch.ass"
BATCH_SIZE = 10


def batch_translate():
    print("ğŸš€ æ­£åœ¨å¯åŠ¨ SakuraLLM æ‰¹é‡ç¿»è¯‘å¼•æ“ (GPU åŠ é€Ÿç‰ˆ)...")
    # ä¿æŒ n_ctx=1024 ç¡®ä¿ 3060 Ti è¿è¡Œç¨³å¥
    llm = Llama(model_path=MODEL_PATH, n_gpu_layers=-1, n_ctx=1024, verbose=False)

    subs = pysubs2.load(INPUT_ASS)
    total = len(subs)

    # é¢„å¤„ç†ï¼šå‰”é™¤ ASS ç‰¹æ•ˆæ ‡ç­¾ï¼Œåªæå–çº¯å‡€çš„å¾…ç¿»è¯‘æ–‡æœ¬
    processed_lines = []
    for line in subs:
        # ä½¿ç”¨ pysubs2 çš„å·¥å…·å‰¥ç¦»æ‰€æœ‰ {\...} æ ‡ç­¾
        # è¿™æ · (ãƒ‰ãƒ­ã‚·ãƒ¼) å‰é¢çš„ç‰¹æ•ˆæ ‡ç­¾å°±ä¸ä¼šå¹²æ‰°æ­£åˆ™äº†
        pure_text = line.plaintext.strip()

        if not pure_text:
            processed_lines.append(None)
            continue

        # å‰¥ç¦»å‰åç¬¦å·ï¼šæ¯”å¦‚æŠŠ â€œï¼ˆãƒ‰ãƒ­ã‚·ãƒ¼ï¼‰â€ æ‹†æˆ â€œï¼ˆâ€, â€œãƒ‰ãƒ­ã‚·ãƒ¼â€, â€œï¼‰â€
        SYMBOL_RE = re.compile(r"^([^\w\u4e00-\u9fa5\u3040-\u30ff]*)[\s]*(.*?)[\s]*([^\w\u4e00-\u9fa5\u3040-\u30ff]*)$")
        match = SYMBOL_RE.match(pure_text)

        prefix, main, suffix = match.groups() if match else ("", pure_text, "")
        processed_lines.append({
            "prefix": prefix,
            "main": main,
            "suffix": suffix,
            "orig_raw": line.text  # ä¿ç•™å¸¦æ ‡ç­¾çš„åŸå¥
        })

    time_s = time.time()

    for i in range(0, total, BATCH_SIZE):
        batch = processed_lines[i: i + BATCH_SIZE]
        to_translate = [b["main"] for b in batch if b is not None and len(b["main"]) > 0]

        if not to_translate:
            continue

        prompt_text = "\n".join([f"{idx + 1}. {text}" for idx, text in enumerate(to_translate)])
        prompt = f"<|im_start|>system\nä½ æ˜¯ä¸€ä¸ªåŠ¨æ¼«ä¸“å®¶ï¼Œè¯·å°†æ—¥æ–‡å°è¯ç¿»è¯‘æˆæµåˆ©çš„ä¸­æ–‡ã€‚æŒ‰åºå·å¯¹åº”ï¼Œä¸è¦å¤šè¨€ï¼Œä¸è¦ä»»ä½•æ ‡ç‚¹ç¬¦å·ã€‚<|im_end|>\n<|im_start|>user\n{prompt_text}<|im_end|>\n<|im_start|>assistant\n"

        output = llm(prompt, max_tokens=512, stop=["<|im_end|>"], echo=False)
        results = output["choices"][0]["text"].strip().split('\n')

        res_idx = 0
        for j in range(len(batch)):
            current_item = batch[j]
            if current_item and len(current_item["main"]) > 0:
                if res_idx < len(results):
                    # 1. åŸºç¡€æ¸…ç†ï¼šå»æ‰åºå·
                    clean_zh = re.sub(r'^\d+[\.ã€\s]*', '', results[res_idx]).strip()
                    # 2. æ·±åº¦æ¸…ç†ï¼šå»æ‰ AI è„‘è¡¥å‡ºæ¥çš„é‡å¤å‰ç¼€æ‹¬å·
                    clean_zh = re.sub(r'^[\(\)ï¼ˆï¼‰ã€Œã€ã€ã€\s]+', '', clean_zh)
                    # 3. æŠ¹é™¤æœ«å°¾æ ‡ç‚¹
                    clean_zh = re.sub(r'[ï¼Œã€‚ï¼ï¼Ÿ,.\?!]+$', '', clean_zh).strip()

                    # ç»„è£…ï¼šä¿ç•™åŸå¥ç‰¹æ•ˆæ ‡ç­¾ä½œä¸ºç¬¬ä¸€è¡Œï¼Œå¹²å‡€çš„ä¸­æ–‡ä½œä¸ºç¬¬äºŒè¡Œ
                    # final_zh ä½¿ç”¨åŸæœ‰çš„ prefix/suffixï¼Œç¡®ä¿ç¬¦å·ä¸é‡å¤
                    final_zh = f"{current_item['prefix']}{clean_zh}{current_item['suffix']}"
                    subs[i + j].text = f"{current_item['orig_raw']}\\N{final_zh}"
                    res_idx += 1
            elif current_item:
                subs[i + j].text = f"{current_item['orig_raw']}\\N{current_item['orig_raw']}"

        print(f"ğŸ“ˆ è¿›åº¦: {min(i + BATCH_SIZE, total)}/{total}")

    subs.save(OUTPUT_ASS)
    time_elapsed = time.time() - time_s
    print(f"âœ¨ ç¿»è¯‘å®Œæˆï¼ç”¨æ—¶ï¼š{round(time_elapsed, 2)}s")


if __name__ == "__main__":
    batch_translate()